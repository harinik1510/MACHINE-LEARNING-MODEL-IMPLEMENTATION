!pip install pandas numpy scikit-learn matplotlib seaborn nltk
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
import string
import re

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

nltk.download('stopwords')
from nltk.corpus import stopwords
# Load both fake and real datasets
fake = pd.read_csv('fake_news.csv')
real = pd.read_csv('True.csv')

# Assign labels: 0 = fake, 1 = real
fake['label'] = 0
real['label'] = 1

# Combine and shuffle
df = pd.concat([fake, real], ignore_index=True)
df = df.sample(frac=1).reset_index(drop=True)
import re
import string
from nltk.corpus import stopwords

stop_words = set(stopwords.words('english'))

def clean_text(text):
    # Lowercase
    text = text.lower()
    
    # Remove punctuation
    text = text.translate(str.maketrans('', '', string.punctuation))
    
    # Remove numbers
    text = re.sub(r'\d+', '', text)
    
    # Remove extra whitespace
    text = text.strip()
    
    # Remove stopwords
    words = text.split()
    words = [word for word in words if word not in stop_words]
    
    return ' '.join(words)
# Clean text
df['text'] = df['text'].apply(clean_text)

# Features and target
X = df['text']
y = df['label']

# Split
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
import random
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import PassiveAggressiveClassifier

# Assuming you already have your dataset loaded and cleaned
# X = df['text']
# y = df['label']

def train_and_predict_dynamic_input(X, y):
    # Ask user for news text
    user_input = input("Enter a news sentence to verify if it's Real or Fake:\n")

    # Random train-test split each time
    X_train, _, y_train, _ = train_test_split(X, y, test_size=0.2, random_state=random.randint(0, 10000))

    # TF-IDF vectorization
    vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)
    X_train_tfidf = vectorizer.fit_transform(X_train)

    # Train model
    model = PassiveAggressiveClassifier(max_iter=50)
    model.fit(X_train_tfidf, y_train)

    # Clean and transform input
    cleaned_input = clean_text(user_input)
    input_vector = vectorizer.transform([cleaned_input])

    # Predict
    prediction = model.predict(input_vector)
    result = "Real News" if prediction[0] == 1 else "Fake News"

    print(f"\nPrediction: {result}")
train_and_predict_dynamic_input(X, y)
